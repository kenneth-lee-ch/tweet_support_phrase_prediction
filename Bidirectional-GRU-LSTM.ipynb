{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics.scorer import make_scorer\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "seed = 221"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27476</td>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27477</td>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27478</td>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27479</td>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27480</td>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27481 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           textID                                               text  \\\n",
       "0      cb774db0d1                I`d have responded, if I were going   \n",
       "1      549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2      088c60f138                          my boss is bullying me...   \n",
       "3      9642c003ef                     what interview! leave me alone   \n",
       "4      358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...           ...                                                ...   \n",
       "27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27479  ed167662a5                         But it was worth it  ****.   \n",
       "27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \n",
       "0                    I`d have responded, if I were going   neutral  \n",
       "1                                               Sooo SAD  negative  \n",
       "2                                            bullying me  negative  \n",
       "3                                         leave me alone  negative  \n",
       "4                                          Sons of ****,  negative  \n",
       "...                                                  ...       ...  \n",
       "27476                                             d lost  negative  \n",
       "27477                                      , don`t force  negative  \n",
       "27478                          Yay good for both of you.  positive  \n",
       "27479                         But it was worth it  ****.  positive  \n",
       "27480  All this flirting going on - The ATG smiles. Y...   neutral  \n",
       "\n",
       "[27481 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**All helper functions are listed below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the helper functions here\n",
    "\n",
    "def makeToken(txt, selected_txt):\n",
    "    \"\"\"\n",
    "        replace the selected text inside a text with the same token\n",
    "    \"\"\"\n",
    "    # Join a list of <token> based on the length of the selected text \n",
    "    tokens = \" \".join(\"<token>\" for i in range(len(selected_txt.split())))\n",
    "    # replace the text where it matches with selected text with token\n",
    "    txt = txt.replace(selected_txt, tokens)\n",
    "    return txt\n",
    "\n",
    "def build_embedding_from_glove(tokenizer, vocab_size):\n",
    "    \"\"\"\n",
    "        turning the tweets in training data to word vectors\n",
    "    \"\"\"\n",
    "    # Part 1: read in the GloVe word embedding\n",
    "    # Empty dictionary\n",
    "    embeddings_index = dict()\n",
    "    f = open('glove.840B.300d.txt')\n",
    "    # Write pretrained word embedding layer to a dictoray\n",
    "    for line in f:\n",
    "        # split up word and the vector\n",
    "        values = line.split(\" \")\n",
    "        # Get an index for that word\n",
    "        word = values[0]\n",
    "        # Put the word vectors as a numpy array\n",
    "        coefs = np.array(values[1:], dtype='float32')\n",
    "        # Put each word vector to map to its index for that word\n",
    "        embeddings_index[word] = coefs\n",
    "    # Close the file\n",
    "    f.close()\n",
    "\n",
    "    # Part 2: Tranform our data based on the word embedding\n",
    "    glove_embedding = np.stack(embeddings_index.values())\n",
    "\n",
    "    # GloVe's word vectors is default to be 300 dimensional, we form a matrix based on sampling from the normal distribution with the same mean and std as the word embedding\n",
    "    #embedding_matrix = np.random.normal(np.mean(glove_embedding), glove_embedding.std(), (vocab_size, 300))\n",
    "    embedding_matrix= np.zeros((vocab_size, 300)) # try all zero matrix\n",
    "    for word, idx in tokenizer.word_index.items():\n",
    "        # Get the word, strip off all non-letter values from the word to hopefully get the corresponding vector from embedding\n",
    "        embedding_vectors = embeddings_index.get(re.sub(r\"[^A-Za-z]\", \"\", word))\n",
    "        # If we can find the corresponding word vector in GloVe, we add it to the embedding matrix\n",
    "        if embedding_vectors is not None:\n",
    "            # Add the vector to the corresponding row according to the index in the tokenizer\n",
    "            embedding_matrix[idx] = embedding_vectors\n",
    "    return embedding_matrix\n",
    "\n",
    "\n",
    "def jaccard(str1, str2): \n",
    "    \"\"\"\n",
    "        an evaluation metric specified by Kaggle\n",
    "    \"\"\"\n",
    "    a = set(str1.lower().split()) \n",
    "    b = set(str2.lower().split())\n",
    "    c = a.intersection(b)\n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))\n",
    "\n",
    "def pad(tokenizer, text, maxlen):\n",
    "    \"\"\"\n",
    "        pad a list of integers with 0 up to the specified maximum length\n",
    "    \"\"\"\n",
    "    # utilize the tokenizer to convert each tweet into a list of integer. These integers are assigned by the tokenizer based on the index of the word in it.\n",
    "    sequence = tokenizer.texts_to_sequences(text)\n",
    "    # Pad the list of integer with 0 to a specified length \n",
    "    padded_sequence  = pad_sequences(sequence,maxlen=maxlen) \n",
    "    return padded_sequence  \n",
    "\n",
    "def decode(text_sequence, binary_sequence, tokenizer):\n",
    "    \"\"\"\n",
    "        get the corresponding word based on the list of 0 and 1\n",
    "    \"\"\"\n",
    "    # Get a list of indicies where the binary sequence has a 1\n",
    "    index_list=[key for key, val in enumerate(binary_sequence) if val == 1] \n",
    "    # Get a list of strings from the tokenizer based on the indicies in text_sequence corresponding to those 1's positions\n",
    "    res_list = [tokenizer.index_word[text_sequence[i]] for i in index_list if text_sequence[i]!=0] \n",
    "    # Get back the sentence\n",
    "    decoded_sentence = \" \".join(res_list)\n",
    "    return decoded_sentence \n",
    "\n",
    "def evaluate(X, y_true, tokenizer, model, eps=0.1):\n",
    "    \"\"\"\n",
    "        evaluate the overall test score\n",
    "    \"\"\"\n",
    "    # predict based on y\n",
    "    y_pred = model.predict_classes(X, verbose=0)\n",
    "    # Transform the data dimension back to the one same as y_test\n",
    "    y_pred = y_pred.reshape(y_true.shape[0],y_true.shape[1])\n",
    "    # Likewise, we tranform X\n",
    "    X = X.reshape(X.shape[0],X.shape[1])\n",
    "    print(y_pred[0])\n",
    "    print(y_true[0])\n",
    "    \n",
    "    ls = []\n",
    "    for row in range(len(y_pred)):\n",
    "        # Decode each row to get the predicted text \n",
    "        decoded_pred_text = decode(X[row], y_pred[row], tokenizer)\n",
    "        # Decode each row to get the actual text \n",
    "        actual_text = decode(X[row], y_true[row], tokenizer)\n",
    "        # compute the score for each row and average them\n",
    "        ls.append(jaccard(decoded_pred_text, actual_text))\n",
    "        overall_score = np.mean(ls)\n",
    "    return overall_score\n",
    "\n",
    "def build_model(num_node, activation_1, activation_2, optimizer, gru):\n",
    "    \"\"\"\n",
    "        A function that builds either bidirectional GRU or LSTM architecture.\n",
    "    \"\"\"\n",
    "    # Model specification\n",
    "    model = Sequential()\n",
    "    #if glove == True:\n",
    "    # Embedding layer: vocab_size is the count of unique token + 1 for the 0 we added, embed size is the size of the vector space for which the words are embedded. \n",
    "    #    model.add(Embedding(vocab_size, 300, weights=[embedding_mat], input_length=(maxlen,), trainable=False))\n",
    "    #else:\n",
    "    #    model.add(Embedding(vocab_size, 300, input_length=(maxlen,), trainable=True))\n",
    "    if gru == True:\n",
    "        # Bidirectional with Graded Recurrent Unit\n",
    "        model.add(Bidirectional(GRU(num_node, dropout = 0.3, return_sequences=True, recurrent_dropout=0.3),input_shape=(maxlen, 1)))\n",
    "    else:\n",
    "        # Bidirectional with LSTM \n",
    "        model.add(Bidirectional(LSTM(num_node, dropout = 0.3, return_sequences=True, recurrent_dropout=0.3),input_shape=(maxlen, 1)))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(Dense(num_node, activation=activation_1, kernel_constraint=max_norm(2))))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(Dense(num_node, activation=activation_2, kernel_constraint=max_norm(2))))\n",
    "    model.add(TimeDistributed(Dropout(0.5)))\n",
    "    model.add(TimeDistributed(Dense(1, activation=\"sigmoid\")))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def tune(X, y, model, grid, num_fold, scoring, random_state):\n",
    "    \"\"\"\n",
    "        this function wraps the methods for grid search cross validation for tuning parameters\n",
    "    Arguements:\n",
    "        X (array): the training samples\n",
    "        y (array):  the response variable\n",
    "        grid(dict): a dictionary contains information about which parameter to be tuned and the respective values involved.\n",
    "        num_fold(int): the number of fold for cross-validation\n",
    "        scoring (str): the scoring metrix\n",
    "    Return:\n",
    "        grid_result (dict) : dict of numpy (masked) ndarrays. See sklearn.model_selection.GridSearchCV for details\n",
    "    \"\"\"\n",
    "    # Grid search cross validation\n",
    "    kfold = KFold(n_splits=num_fold, random_state=random_state)\n",
    "    # Utilize all CPUs and assign 0 score if the error occurs. \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=grid, cv= kfold, scoring=scoring, error_score=0)\n",
    "    grid_result = grid_search.fit(X,y)\n",
    "    # print the best result and respective parameter based on residual sum of squares \n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    return grid_result\n",
    "\n",
    "def plotLoss(history):\n",
    "    \"\"\"\n",
    "        plot the loss for the neural net training process\n",
    "    \"\"\"\n",
    "    # summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    \n",
    "def plotAccuracy(history):\n",
    "    \"\"\"\n",
    "        plot the accuracy of the neural net training process\n",
    "    \"\"\"\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuning the selected text inside the text with the same label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>textID</th>\n",
       "      <th>text</th>\n",
       "      <th>selected_text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>tokenized_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>cb774db0d1</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>I`d have responded, if I were going</td>\n",
       "      <td>neutral</td>\n",
       "      <td>&lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;toke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>549e992a42</td>\n",
       "      <td>Sooo SAD I will miss you here in San Diego!!!</td>\n",
       "      <td>Sooo SAD</td>\n",
       "      <td>negative</td>\n",
       "      <td>&lt;token&gt; &lt;token&gt; I will miss you here in San D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>088c60f138</td>\n",
       "      <td>my boss is bullying me...</td>\n",
       "      <td>bullying me</td>\n",
       "      <td>negative</td>\n",
       "      <td>my boss is &lt;token&gt; &lt;token&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9642c003ef</td>\n",
       "      <td>what interview! leave me alone</td>\n",
       "      <td>leave me alone</td>\n",
       "      <td>negative</td>\n",
       "      <td>what interview! &lt;token&gt; &lt;token&gt; &lt;token&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>358bd9e861</td>\n",
       "      <td>Sons of ****, why couldn`t they put them on t...</td>\n",
       "      <td>Sons of ****,</td>\n",
       "      <td>negative</td>\n",
       "      <td>&lt;token&gt; &lt;token&gt; &lt;token&gt; why couldn`t they put...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27475</td>\n",
       "      <td>27476</td>\n",
       "      <td>4eac33d1c0</td>\n",
       "      <td>wish we could come see u on Denver  husband l...</td>\n",
       "      <td>d lost</td>\n",
       "      <td>negative</td>\n",
       "      <td>wish we could come see u on Denver  husban&lt;to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27476</td>\n",
       "      <td>27477</td>\n",
       "      <td>4f4c4fc327</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "      <td>, don`t force</td>\n",
       "      <td>negative</td>\n",
       "      <td>I`ve wondered about rake to.  The client has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27477</td>\n",
       "      <td>27478</td>\n",
       "      <td>f67aae2310</td>\n",
       "      <td>Yay good for both of you. Enjoy the break - y...</td>\n",
       "      <td>Yay good for both of you.</td>\n",
       "      <td>positive</td>\n",
       "      <td>&lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;toke...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27478</td>\n",
       "      <td>27479</td>\n",
       "      <td>ed167662a5</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>But it was worth it  ****.</td>\n",
       "      <td>positive</td>\n",
       "      <td>&lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;token&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27479</td>\n",
       "      <td>27480</td>\n",
       "      <td>6f7127d9d7</td>\n",
       "      <td>All this flirting going on - The ATG smiles...</td>\n",
       "      <td>All this flirting going on - The ATG smiles. Y...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>&lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;token&gt; &lt;to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27480 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index      textID                                               text  \\\n",
       "0          0  cb774db0d1                I`d have responded, if I were going   \n",
       "1          1  549e992a42      Sooo SAD I will miss you here in San Diego!!!   \n",
       "2          2  088c60f138                          my boss is bullying me...   \n",
       "3          3  9642c003ef                     what interview! leave me alone   \n",
       "4          4  358bd9e861   Sons of ****, why couldn`t they put them on t...   \n",
       "...      ...         ...                                                ...   \n",
       "27475  27476  4eac33d1c0   wish we could come see u on Denver  husband l...   \n",
       "27476  27477  4f4c4fc327   I`ve wondered about rake to.  The client has ...   \n",
       "27477  27478  f67aae2310   Yay good for both of you. Enjoy the break - y...   \n",
       "27478  27479  ed167662a5                         But it was worth it  ****.   \n",
       "27479  27480  6f7127d9d7     All this flirting going on - The ATG smiles...   \n",
       "\n",
       "                                           selected_text sentiment  \\\n",
       "0                    I`d have responded, if I were going   neutral   \n",
       "1                                               Sooo SAD  negative   \n",
       "2                                            bullying me  negative   \n",
       "3                                         leave me alone  negative   \n",
       "4                                          Sons of ****,  negative   \n",
       "...                                                  ...       ...   \n",
       "27475                                             d lost  negative   \n",
       "27476                                      , don`t force  negative   \n",
       "27477                          Yay good for both of you.  positive   \n",
       "27478                         But it was worth it  ****.  positive   \n",
       "27479  All this flirting going on - The ATG smiles. Y...   neutral   \n",
       "\n",
       "                                          tokenized_text  \n",
       "0       <token> <token> <token> <token> <token> <toke...  \n",
       "1       <token> <token> I will miss you here in San D...  \n",
       "2                          my boss is <token> <token>...  \n",
       "3                what interview! <token> <token> <token>  \n",
       "4       <token> <token> <token> why couldn`t they put...  \n",
       "...                                                  ...  \n",
       "27475   wish we could come see u on Denver  husban<to...  \n",
       "27476   I`ve wondered about rake to.  The client has ...  \n",
       "27477   <token> <token> <token> <token> <token> <toke...  \n",
       "27478    <token> <token> <token> <token> <token> <token>  \n",
       "27479     <token> <token> <token> <token> <token> <to...  \n",
       "\n",
       "[27480 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess: drop the missing value and tokenize all selected text in a text\n",
    "train = train.dropna().reset_index()\n",
    "\n",
    "# Replace the selected text in text with a specified token\n",
    "storage = []\n",
    "for row in range(train.shape[0]):\n",
    "    list_of_targets = makeToken(train[\"text\"][row], train[\"selected_text\"][row])\n",
    "    storage.append(list_of_targets)\n",
    "train[\"tokenized_text\"] = pd.DataFrame(storage)\n",
    "train "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenization: Assign an integer index to all the words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize all text in the text column and the <token> in the tokenized text\n",
    "tokenizer = Tokenizer(filters='') # specify filter so that it won't strip off the <> for token\n",
    "tokenizer.fit_on_texts(pd.concat([train.text, train.tokenized_text], axis=0)) # fit in all text to be tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build an embedding matrix based on GloVe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a matrix that utilize indicies from tokenizer and the learned word embedding from Glove\n",
    "#vocab_size = len(tokenizer.word_index) + 1\n",
    "#embedding_mat = build_embedding_from_glove(tokenizer, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all the word that has \"<token>\" in it to have the same index since there are some \"<token>..\"\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    if \"<token>\" in word:\n",
    "        # set any words that contain <token> to have the same index\n",
    "        tokenizer.word_index[word] = tokenizer.word_index[\"<token>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the longest text in the data for padding other shorter text\n",
    "maxlen = max(train[\"text\"].apply(lambda x: len(x.split())))\n",
    "\n",
    "# Tranform the text into a list of integer and pad it with 0. The maximum length of padding is the length of the longest text in data\n",
    "X = pad(tokenizer, train.text, maxlen)\n",
    "y = pad(tokenizer, train.tokenized_text, maxlen)\n",
    "\n",
    "# Binarize the signal in y\n",
    "# If the text is a token we call it 1 and 0 otherwise\n",
    "y[y != tokenizer.word_index[\"<token>\"]] = 0\n",
    "y[y == tokenizer.word_index[\"<token>\"]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting Training and Testing Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "# Transform the data dimension\n",
    "X_tr_v = np.array(X_train).reshape(X_train.shape[0],X_train.shape[1],1).astype(np.float32) # Change the data type\n",
    "X_te_v = np.array(X_test).reshape(X_test.shape[0],X_test.shape[1],1).astype(np.float32) # Change the data type\n",
    "y_tr_v = np.array(y_train).reshape(y_train.shape[0],y_train.shape[1],1)\n",
    "y_te_v = np.array(y_test).reshape(y_test.shape[0],y_test.shape[1],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial search for number epoch with some fixed parameters with the proposed model**\n",
    "\n",
    "* 20 epoches is enough for training the model based on the loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define SGD optimizer\n",
    "sgd = SGD(lr=0.1, momentum=0.9)\n",
    "# Instantiate a GRU with embedding based on GloVe\n",
    "glove_emd_GRU_model = build_model(20,\"tanh\", \"relu\", sgd, gru=True)\n",
    "# Fit the model\n",
    "history = glove_emd_GRU_model.fit(X_tr_v, y_tr_v, batch_size=32,epochs=100,validation_data=(X_te_v,y_te_v),verbose=0)\n",
    "plotLoss(history)\n",
    "# Evaluate the model with prob_threshold 0.1\n",
    "print(evaluate(X_te_v, y_test,tokenizer, glove_emd_GRU_model))\n",
    "print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try a different optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "adam = 'adam'\n",
    "# Instantiate a GRU with embedding based on GloVe\n",
    "glove_emd_GRU_model = build_model(20,\"tanh\", \"relu\", adam, gru=True)\n",
    "# Fit the model\n",
    "history = glove_emd_GRU_model.fit(X_tr_v, y_tr_v, batch_size=32,epochs=40,validation_data=(X_te_v,y_te_v),verbose=0)\n",
    "plotLoss(history)\n",
    "# Evaluate the model\n",
    "print(evaluate(X_te_v, y_test, tokenizer, glove_emd_GRU_model))\n",
    "print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Tuning with 60 epochs**\n",
    "\n",
    "We stick with SGD optimizer and use 60 epochs to tune all the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters to tune\n",
    "activation = ['tanh', 'relu', 'sigmoid'] # activations\n",
    "node_num = [20,30,64] # width of the layer\n",
    "gru = [True, False]\n",
    "# Due to the large number of parameters to tune, we print the result out so that the memory won't get overloaded\n",
    "for g in gru:\n",
    "    for n in node_num:\n",
    "        for a1 in activation:\n",
    "            for a2 in activation:\n",
    "                # Instantiate a GRU with embedding based on GloVe\n",
    "                model = build_model(n, a1, a2, sgd, gru=g)\n",
    "                # Fit the model\n",
    "                history = model.fit(X_tr_v, y_tr_v, batch_size=32,epochs=60,validation_data=(X_te_v,y_te_v),verbose=0)\n",
    "                # Evaluate the model \n",
    "                print(\"GRU?\", g)\n",
    "                print(\"Number of nodes: \",n)\n",
    "                print(\"Activation 1:\", a1)\n",
    "                print(\"Activation 2:\", a2)\n",
    "                print(\"Jaccard Score: \", evaluate(X_te_v, y_test,tokenizer, model))\n",
    "                print(\"--------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_v = np.array(X).reshape(X.shape[0],X.shape[1],1).astype(np.float32) # Change the data type\n",
    "y_v = np.array(y).reshape(y.shape[0],y.shape[1],1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**K-Fold Cross-Validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 10-fold cross validation test harness\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X_v, y_v):\n",
    "    model = build_model(20, \"tanh\", \"relu\", sgd, gru=True)# finalize model\n",
    "    model.fit(X_v[train], y_v[train], epochs=60, batch_size=32, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_v[test], y_v[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 10-fold cross validation test harness\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "cvscores = []\n",
    "for train, test in kfold.split(X_v, y_v):\n",
    "    model = build_model(20, \"relu\",  \"tanh\", sgd, gru=False)# finalize model\n",
    "    model.fit(X_v[train], y_v[train], epochs=60, batch_size=32, verbose=0)\n",
    "    # evaluate the model\n",
    "    scores = model.evaluate(X_v[test], y_v[test], verbose=0)\n",
    "    print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    cvscores.append(scores[1] * 100)\n",
    "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit in all data to submit for \n",
    "lstm = build_model(20, \"relu\",  \"tanh\", sgd, gru=False)\n",
    "lstm.fit(X_v, y_v, epochs=60, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x13ca92710>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit in all data to submit for \n",
    "sgd = SGD(lr=0.1, momentum=0.9)\n",
    "gru = build_model(20, \"relu\",  \"tanh\", sgd, gru=True)\n",
    "gru.fit(X_v, y_v, epochs=60, batch_size=32, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a submission using GRU\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "sub_test = pad_sequences(tokenizer.texts_to_sequences(test.text), maxlen = maxlen)\n",
    "# Transform the data dimension\n",
    "sub_test = np.array(sub_test).reshape(sub_test.shape[0],sub_test.shape[1],1).astype(np.float32)\n",
    "sub_test_pred = gru.predict_classes(sub_test)\n",
    "sub_test_pred = sub_test_pred.reshape(sub_test_pred.shape[0],sub_test_pred.shape[1])\n",
    "\n",
    "# Transform X back\n",
    "sub_test = sub_test.reshape(sub_test.shape[0],sub_test.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 1 1 1]\n",
      " [0 0 0 ... 1 1 1]\n",
      " [0 0 0 ... 1 1 1]\n",
      " ...\n",
      " [0 0 0 ... 1 1 1]\n",
      " [0 0 0 ... 1 1 1]\n",
      " [0 0 0 ... 1 1 1]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "# Make a submission using GRU\n",
    "submission = pd.read_csv('data/sample_submission.csv')\n",
    "sub_test = pad_sequences(tokenizer.texts_to_sequences(test.text), maxlen = maxlen)\n",
    "# Transform the data dimension\n",
    "sub_test = np.array(sub_test).reshape(sub_test.shape[0],sub_test.shape[1],1).astype(np.float32)\n",
    "sub_test_pred = gru.predict_classes(sub_test, verbose=0)\n",
    "sub_test_pred = sub_test_pred.reshape(sub_test_pred.shape[0],sub_test_pred.shape[1])\n",
    "# Transform X back\n",
    "sub_test = sub_test.reshape(sub_test.shape[0],sub_test.shape[1])\n",
    "\n",
    "for i in range(len(sub_test_pred)):\n",
    "  # Decode and fill in the file\n",
    "  submission[\"selected_text\"][i] = decode(sub_test[i], sub_test_pred[i], tokenizer)\n",
    "#Write to a csv file\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
